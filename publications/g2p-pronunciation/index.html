<!doctype html>
<html>

<head>
  <title>Innoetics</title>
  <style>
    .container {
      padding: 12px 24px;
    }

    .head-container {
      /* border: 5px solid gray; */
      border-radius: 25px;
      /* border: 1px solid; */
      border-color: rgba(0,0,0,0.2);
      text-align: center;
      padding: 16px;
      margin: 0px 200px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
      transition: 0.3s;
    }

    .head-container:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(250, 250, 255);
    }

    .sample-container {
      margin: 18px 0;
    }

    .sample {
      /* border: 1px solid gray;
      border-radius: 10px; */
      padding: 10px;
      margin: 10px;
      width: 80%;
      position: relative;
      display: block;
      text-align: left;
    }

    .sample-title {
      font-size: 22px;
      margin: 8px 0;
      display: inline-flex;
    }

    .sample-description {
      font-size: 16px;
      margin: 8px 0;
      color: #868686e6;
    }

    .sample-audio {
      margin: 14px 0;
      display: flex;
      align-items: center;
      justify-content: left;
      padding-left: 50px;
    }

    .quotation {
      font-size: xxx-large;
      color: rgb(152, 189, 253);
      margin-top: -12px;
    }

    .transcript {
      display: inline;
      font-style: italic;
      background-color: rgb(231, 239, 253);
      padding: 15px 15px;
      border-radius: 25px;
    }

    audio {
      height: 35px;
      /* vertical-align: middle; */
      /* margin-top: -9px; */
    }

    .r-number {
      width: 24px;
      text-align: center;
      /* display: inline-block;   */
      margin-right: 8px;
      background-color: rgb(231, 239, 253);
      border-radius: 25px;
      padding: 10px;
    }
  </style>
</head>

<body class="container">
  <div class="head-container">
  <h1 style="text-align: center;">An Iterative Seq2Seq-Supported Method for Crowd-Sourcing and Evaluating Phonetic Lexical Resources of Out-Of-Vocabulary Words</h1>
  <p style="text-align: center;font-size: 20px;">Georgia Maniati,
    Aimilios Chalamandaris,
    Georgios Vamvoukakis,
    Nikolaos Ellinas,
    Panos Kakoulidis,
    Georgios Dimitriou,
    Konstantinos Markopoulos,
    Pirros Tsiakoulis,
    Spyros Raptis,
    Gunu Jho,
    June Sig Sung,
    Jihyeok Yoon,
    Hyoungmin Park</p>
  <p style="text-align: left;font-size: 18px;"><strong>Abstract:</strong> In this paper, we describe a method for compiling large and accurate pronunciation lexica for out-of-vocabulary words for text-to-speech synthesis. The method combines a neural sequence-to-sequence grapheme-to-phoneme (G2P) model, a state-of-the-art text-to-speech system and crowdsourced evaluation. For each out-of-vocabulary word, we generate multiple alternative pronunciations using the G2P model and convert them into speech. The synthesized pronunciations are then validated using a custom preference test by multiple non-linguistic-expert users via the Amazon Mechanical Turk. The alternatives that exceed a threshold majority of preference among the listeners are considered correct and added to the pronunciation lexicon used to train the neural G2P model. The entire process is iterated by first retraining the neural G2P model and then evaluating additional out-of-vocabulary words. We analyze the quality of the resulting pronunciation resources and demonstrate that, through this process, we can quickly scale up pronunciation lexica and increase the robustness of the neural G2P model.</p>
  </div>
</body>
</html>
