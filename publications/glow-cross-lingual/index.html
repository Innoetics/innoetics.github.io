<!doctype html>
<html>

<head>
  <title>Innoetics</title>
  <style>
    .container {
      padding: 12px 24px;
      overflow: scroll;
    }

    .head-container {
      /* border: 5px solid gray; */
      border-radius: 25px;
      /* border: 1px solid; */
      border-color: rgba(0,0,0,0.2);
      text-align: center;
      padding: 16px;
      margin: 0px 200px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
      transition: 0.3s;
    }

    .head-container:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(250, 250, 255);
    }

    .tooltip {
      position: relative;
      display: inline-block;
      cursor: pointer;
    }


    .tooltip .tooltiptext {
      visibility: hidden;
      width: 120px;
      background-color: black;
      color: #fff;
      text-align: center;
      padding: 5px 0;
      border-radius: 6px;
      position: absolute;
      z-index: 1;
      cursor: pointer;
    }

    .tooltip:hover .tooltiptext {
      visibility: visible;
      cursor: pointer;
    }

    .sample-container {
      margin: 18px 0;
    }

    .sample {
      /* border: 1px solid gray;
      border-radius: 10px; */
      padding: 10px;
      margin: 10px;
      width: 80%;
      position: relative;
      display: block;
      text-align: left;
    }

    .sample-title {
      font-size: 22px;
      margin: 8px 0;
      display: inline-flex;
    }

    .sample-description {
      font-size: 16px;
      margin: 8px 0;
      color: #868686e6;
    }

    .mod-container {
      display: flex;
    }

    .sample-audio {
      margin: 10px 0;
      display: inline-block;
      align-items: center;
      justify-content: left;
      padding-left: 10px;
    }

    .quotation {
      font-size: xxx-large;
      color: rgb(152, 189, 253);
      margin-top: -12px;
    }

    .transcript {
      display: inline;
      font-style: italic;
      background-color: rgb(231, 239, 253);
      padding: 15px 15px;
      border-radius: 25px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
      transition: 0.1s;
    }

    audio {
      height: 35px;
      display: none;
    }

    .r-number {
      width: 24px;
      text-align: center;
      margin-right: 8px;
      background-color: rgb(231, 239, 253);
      border-radius: 25px;
      padding: 10px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    }

    .r-number:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(222, 230, 253);
      cursor: pointer;
    }

    .r-number-aug {
      width: 48px;
      text-align: center;
      margin-right: 8px;
      background-color: rgb(231, 239, 253);
      border-radius: 25px;
      padding: 10px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    }

    .r-number-aug:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(222, 230, 253);
      cursor: pointer;
    }

    .gt {
      width: 109px;
      text-align: center;
      margin-right: 0px;
      background-color: rgb(231, 239, 253);
      border-radius: 25px;
      padding: 10px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    }

    .gt:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(222, 230, 253);
      cursor: pointer;
    }

    .gt.speaker {
      width: 100px;
    }

    .note {
      text-align: center;
      background-color: rgb(231, 239, 253);
      padding: 10px;
      border-radius: 25px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
      transition: 0.1s;
    }

    .note:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(222, 230, 253);
      cursor: pointer;
    }

    .invisible {
      width: 100px;
      text-align: center;
      margin-right: 8px;
      border-radius: 25px;
      padding: 10px;
    }

    .invisible.axis {
      width: 100px;
      text-align: center;
      margin-right: 8px;
      background-color: rgb(200, 200, 253);
      border-radius: 25px;
      padding: 10px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    }

    h2:hover {
      cursor: pointer;
      background: silver;
    }

    h2 {
      border: azure;
      background: bisque;
      border-radius: 10px;
      padding: 10px;
    }

    a.custom-a-href {
      color: black;
      text-decoration: none;
    }

    html {
      scroll-behavior: smooth;
    }

  </style>
</head>

<body class="container">
  <script >
    function togglePlay(el) {
      if (!el.paused) {
        el.pause()
      }
      else {
        var allAudioEls = document.getElementsByTagName("audio");
        for (let item of allAudioEls) {
            item.pause()
        }
        el.currentTime = 0;
        el.play();
      }
    };
    function showSample(event) {
      var target = event.target || event.srcElement;
      var currentDisplayAttrValue = target.parentElement.nextElementSibling.style.display;
      target.parentElement.nextElementSibling.style.display =  currentDisplayAttrValue == 'none' ? 'block' : 'none';
    };
  </script>
  <div class="head-container">
    <h1 style="text-align: center;">Cross-lingual text-to-speech with flow-based voice conversion for improved pronunciation</h1>
    <p style="text-align: center;font-size: 20px;">
      Nikolaos Ellinas,
      Georgios Vamvoukakis,
      Konstantinos Markopoulos,
      Georgia Maniati,
      Panos Kakoulidis,
      June Sig Sung,
      Inchul Hwang,
      Spyros Raptis,
      Aimilios Chalamandaris and 
      Pirros Tsiakoulis</p>
    <p style="text-align: left;font-size: 18px;"><strong>Abstract:</strong> This paper presents a method for end-to-end multilingual text-to-speech (TTS) which preserves the target language's pronunciation regardless of the original speaker's language.
      The model used is based on a non-attentive Tacotron architecture, where the decoder has been replaced with a normalizing flow network conditioned on the speaker identity, allowing both TTS and voice conversion (VC) to be performed by the same model.
      We take advantage of how the flow-based decoder can produce distributions that preserve the linguistic content independent of the speaker identity.
      When used in a cross-lingual setting, TTS is first performed with a native speaker of the target language and then voice conversion is applied by the same model in order to convert the produced speech to the target speakerâ€™s voice.
      This method results in more accurate target language pronunciation than the baseline cross-lingual synthesis, as verified by the experimental results.
      Furthermore, we show that similarly high quality multilingual TTS can be achieved for limited resource speakers.</p>
    </div>
</body>
</html>
