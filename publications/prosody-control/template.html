<!doctype html>
<html>

<head>
  <title>Innoetics</title>
  <style>
    .container {
      padding: 12px 24px;
    }

    .head-container {
      /* border: 5px solid gray; */
      border-radius: 25px;
      /* border: 1px solid; */
      border-color: rgba(0,0,0,0.2);
      text-align: center;
      padding: 16px;
      margin: 0px 200px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
      transition: 0.3s;
    }

    .head-container:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(250, 250, 255);
    }

    .tooltip {
      position: relative;
      display: inline-block;
      cursor: pointer;
    }


    .tooltip .tooltiptext {
      visibility: hidden;
      width: 120px;
      background-color: black;
      color: #fff;
      text-align: center;
      padding: 5px 0;
      border-radius: 6px;
      position: absolute;
      z-index: 1;
      cursor: pointer;
    }

    .tooltip:hover .tooltiptext {
      visibility: visible;
      cursor: pointer;
    }

    .sample-container {
      margin: 18px 0;
      display: none;
    }

    .sample {
      /* border: 1px solid gray;
      border-radius: 10px; */
      padding: 10px;
      margin: 10px;
      width: 80%;
      position: relative;
      display: block;
      text-align: left;
    }

    .sample-title {
      font-size: 22px;
      margin: 8px 0;
      display: inline-flex;
    }

    .sample-description {
      font-size: 16px;
      margin: 8px 0;
      color: #868686e6;
    }

    .mod-container {
      display: flex;
    }

    .sample-audio {
      margin: 10px 0;
      display: inline-block;
      align-items: center;
      justify-content: left;
      padding-left: 25px;
    }

    .quotation {
      font-size: xxx-large;
      color: rgb(152, 189, 253);
      margin-top: -12px;
    }

    .transcript {
      display: inline;
      font-style: italic;
      background-color: rgb(231, 239, 253);
      padding: 15px 15px;
      border-radius: 25px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
      transition: 0.1s;
    }

    audio {
      height: 35px;
      display: none;
    }

    .r-number {
      width: 24px;
      text-align: center;
      margin-right: 8px;
      background-color: rgb(231, 239, 253);
      border-radius: 25px;
      padding: 10px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    }

    .r-number:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(222, 230, 253);
      cursor: pointer;
    }

    .r-number-aug {
      width: 48px;
      text-align: center;
      margin-right: 8px;
      background-color: rgb(231, 239, 253);
      border-radius: 25px;
      padding: 10px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    }

    .r-number-aug:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(222, 230, 253);
      cursor: pointer;
    }

    .gt {
      width: 109px;
      text-align: center;
      margin-right: 0px;
      background-color: rgb(231, 239, 253);
      border-radius: 25px;
      padding: 10px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    }

    .gt:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(222, 230, 253);
      cursor: pointer;
    }

    .note {
      text-align: center;
      background-color: rgb(231, 239, 253);
      padding: 10px;
      border-radius: 25px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
      transition: 0.1s;
    }

    .note:hover {
      box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2);
      background-color: rgb(222, 230, 253);
      cursor: pointer;
    }

    .invisible {
      width: 48px;
      text-align: center;
      margin-right: 8px;
      border-radius: 25px;
      padding: 10px;
    }

    .invisible.axis {
      width: 48px;
      text-align: center;
      margin-right: 8px;
      background-color: rgb(200, 200, 253);
      border-radius: 25px;
      padding: 10px;
      box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    }

    h2:hover {
      cursor: pointer;
      background: silver;
    }

    h2 {
      border: azure;
      background: bisque;
      border-radius: 10px;
      padding: 10px;
    }

  </style>
</head>

<body class="container">
  <script >
    function togglePlay(el) {
      if (!el.paused) {
        el.pause()
      }
      else {
        var allAudioEls = document.getElementsByTagName("audio");
        for (let item of allAudioEls) {
            item.pause()
        }
        el.currentTime = 0;
        el.play();
      }
    };
    function showSample(event) {
      var target = event.target || event.srcElement;
      var currentDisplayAttrValue = target.nextElementSibling.style.display;
      target.nextElementSibling.style.display =  currentDisplayAttrValue == 'none' ? 'block' : 'none'; 
    };
  </script>
  <div class="head-container">
  <h1 style="text-align: center;">Prosodic Clustering for Phoneme-level Prosody Control in End-to-end Speech Synthesis</h1>
  <p style="text-align: center;font-size: 20px;">Alexandra Vioni<span class="tooltip">*<span class="tooltiptext">Equal Contribution</span></span>,
      Myrsini Christidou<span class="tooltip">*<span class="tooltiptext">Equal Contribution</span></span>,
      Nikolaos Ellinas,
      Georgios Vamvoukakis,
      Panos Kakoulidis,
      Taehoon Kim,
      June Sig Sung,
      Hyoungmin Park,
      Aimilios Chalamandaris and Pirros Tsiakoulis</p>
  <p style="text-align: left;font-size: 18px;"><strong>Abstract:</strong> This paper presents a method for controlling the prosody at the phoneme level in an autoregressive attention-based text-to-speech system.
    Instead of learning latent prosodic features with a variational framework as is commonly done,
    we directly extract phoneme-level F0 and duration features from the speech data in the training set.
    Each prosodic feature is discretized using unsupervised clustering
    in order to produce a sequence of prosodic labels for each utterance.
    This sequence is used in parallel to the phoneme sequence in order to condition the decoder with the utilization of a prosodic encoder and a corresponding attention module.
    Experimental results show that the proposed method retains the high quality of generated speech, while allowing phoneme-level control of F0 and duration.
    By replacing the F0 cluster centroids with musical notes, the model can also provide control over the note and octave within the range of the speaker.</p>
  </div>
